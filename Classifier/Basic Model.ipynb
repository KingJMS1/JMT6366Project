{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "601ab679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "import json \n",
    "\n",
    "import pprint\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from preprocessor import get_train_environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d163e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found cached folds, using those\n",
      "0\n",
      "XGBClassifier start\n",
      "XGBClassifier end\n",
      "RandomForestClassifier start\n",
      "RandomForestClassifier end\n",
      "XGBRegressor start\n",
      "XGBRegressor end\n",
      "RandomForestRegressor start\n",
      "RandomForestRegressor end\n",
      "1\n",
      "XGBClassifier start\n",
      "XGBClassifier end\n",
      "RandomForestClassifier start\n",
      "RandomForestClassifier end\n",
      "XGBRegressor start\n",
      "XGBRegressor end\n",
      "RandomForestRegressor start\n",
      "RandomForestRegressor end\n",
      "2\n",
      "XGBClassifier start\n",
      "XGBClassifier end\n",
      "RandomForestClassifier start\n",
      "RandomForestClassifier end\n",
      "XGBRegressor start\n",
      "XGBRegressor end\n",
      "RandomForestRegressor start\n",
      "RandomForestRegressor end\n",
      "3\n",
      "XGBClassifier start\n",
      "XGBClassifier end\n",
      "RandomForestClassifier start\n",
      "RandomForestClassifier end\n",
      "XGBRegressor start\n",
      "XGBRegressor end\n",
      "RandomForestRegressor start\n",
      "RandomForestRegressor end\n",
      "4\n",
      "XGBClassifier start\n",
      "XGBClassifier end\n",
      "RandomForestClassifier start\n",
      "RandomForestClassifier end\n",
      "XGBRegressor start\n",
      "XGBRegressor end\n",
      "RandomForestRegressor start\n",
      "RandomForestRegressor end\n"
     ]
    }
   ],
   "source": [
    "envGen = get_train_environment(n_splits=5)\n",
    "stats, X, X_holdout, y, y_holdout = next(envGen)\n",
    "\n",
    "xgb_class_scores = []\n",
    "rf_class_scores = []\n",
    "xgb_reg_scores = []\n",
    "rf_reg_scores = []\n",
    "\n",
    "for fold, stats, X_train, X_test, y_train, y_test in envGen:\n",
    "    print(fold)\n",
    "    if len(X_train) == 0 or len(X_test) == 0:\n",
    "        print(f\"Skipping empty fold: {fold}\")\n",
    "        continue\n",
    "    class_y_train = [0 if value == 0 else 1 for value in y_train]\n",
    "    class_y_test = [0 if value == 0 else 1 for value in y_test]\n",
    "    # Create and fit the model\n",
    "    print(\"XGBClassifier start\")\n",
    "    model_xgb_class = XGBClassifier()\n",
    "    model_xgb_class.fit(X_train, class_y_train)\n",
    "    print(\"XGBClassifier end\")\n",
    "    \n",
    "    print(\"RandomForestClassifier start\")\n",
    "    model_rf_class = RandomForestClassifier()\n",
    "    model_rf_class.fit(X_train, class_y_train)\n",
    "    print(\"RandomForestClassifier end\")\n",
    "    \n",
    "    print(\"XGBRegressor start\")\n",
    "    model_xgb_reg = XGBRegressor()\n",
    "    model_xgb_reg.fit(X_train, y_train)\n",
    "    print(\"XGBRegressor end\")\n",
    "    \n",
    "    print(\"RandomForestRegressor start\")\n",
    "    model_rf_reg = RandomForestRegressor()\n",
    "    model_rf_reg.fit(X_train, y_train)\n",
    "    print(\"RandomForestRegressor end\")\n",
    "\n",
    "    # Predict and evaluate\n",
    "    predictions_xgb_class = model_xgb_class.predict(X_test)\n",
    "    accuracy_xgb_class = accuracy_score(class_y_test, predictions_xgb_class)\n",
    "    xgb_class_scores.append(accuracy_xgb_class)\n",
    "    \n",
    "    predictions_rf_class = model_rf_class.predict(X_test)\n",
    "    accuracy_rf_class = accuracy_score(class_y_test, predictions_rf_class)\n",
    "    rf_class_scores.append(accuracy_rf_class)\n",
    "\n",
    "    predictions_xgb_reg = model_xgb_reg.predict(X_test)\n",
    "    mse_xgb_reg = mean_squared_error(y_test, predictions_xgb_reg)\n",
    "    xgb_reg_scores.append(mse_xgb_reg)\n",
    "    \n",
    "    predictions_rf_reg = model_rf_reg.predict(X_test)\n",
    "    mse_rf_reg = mean_squared_error(y_test, predictions_rf_reg)\n",
    "    rf_reg_scores.append(mse_rf_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53b9223b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier Accuracy: 0.9668147028833278\n",
      "RandomForest Classifier Accuracy: 0.9596281057730216\n",
      "XGB Regressor MSE: 0.34283483644459334\n",
      "RandomForest Regressor MSE: 0.3624150952451909\n"
     ]
    }
   ],
   "source": [
    "print(\"XGB Classifier Accuracy:\",np.mean(xgb_class_scores))\n",
    "print(\"RandomForest Classifier Accuracy:\",np.mean(rf_class_scores))\n",
    "print(\"XGB Regressor MSE:\",np.mean(xgb_reg_scores))\n",
    "print(\"RandomForest Regressor MSE:\",np.mean(rf_reg_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d19d048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
